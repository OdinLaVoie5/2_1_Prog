{
    "cells": [
        {
            "cell_type": "markdown",
            "id": "a82cff40",
            "metadata": {},
            "source": [
                "–¥–±     –ü–†–û–í–ï–†–ö–ê –ü–û–†–û–®–ö–ê \n",
                "    1 –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è —Å—Ç—Ä–æ–∫ ‚Üí lines (—É–±–∏—Ä–∞–µ–º –≤—Å—ë, –∫—Ä–æ–º–µ –±—É–∫–≤ –∏ –ø—Ä–æ–±–µ–ª–æ–≤, –æ–¥–∏–Ω –ø—Ä–æ–±–µ–ª –º–µ–∂–¥—É —Å–ª–æ–≤–∞–º–∏, lower, –ø–µ—Ä–≤—ã–µ 4 —Å—Ç—Ä–æ–∫–∏)\n",
                "    2 accentize_text ‚Üí accented (RUAccent —Å +)\n",
                "    3 plus_to_upper ‚Üí accented_big (–ø—Ä–µ–≤—Ä–∞—â–∞–µ–º +x ‚Üí X)\n",
                "    4 accent_one_and_yo ‚Üí accented_special (–ø—Ä–∞–≤–∏–ª–∞ –ø–æ –æ–¥–Ω–æ—Å–ª–æ–∂–∫–∞–º –∏ —ë)\n",
                "    5 –ø—Ä–æ–≤–µ—Ä–∫–∏: count_syllables –∏ line_stresses (—É–¥–∞—Ä–µ–Ω–∏—è ‚Äî –∑–∞–≥–ª–∞–≤–Ω—ã–µ –≥–ª–∞—Å–Ω—ã–µ)  \n",
                "    6 —Ç–∞–±–ª–∏—Ü–∞  –∏  –æ—Ç—á—ë—Ç\n"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "d735055d",
            "metadata": {},
            "source": [
                "–¥–±    –ü–†–û–ë–õ–ï–ú–´  \n",
                "    \n",
                "    1 ruaccent –µ –∏–Ω–æ–≥–¥–∞ –≤ —ë.  —Å–¥–µ–ª–∞—Ç—å –≤–æ–∑–≤—Ä–∞—Ç –≤—Å–µ—Ö –∏–∑–º–µ–Ω—ë–Ω–Ω—ã—Ö –±—É–∫–≤    (–ï –≤ –Å ?)  (—ë –≤ –µ ?) (–Å –≤ –ï ?)      –≤–æ–∑–≤—Ä–∞—â–∞—Ç—å –Ω–µ —Ç–æ–ª—å–∫–æ –∏—Å–∫–∞–∂–µ–Ω–Ω—ã–µ –µ-—ë  –Ω–æ –∏ –¥—Ä –±—É–∫–≤–∞ (–æ—Ä—Ñ–æ—é–º–æ—Ä)\n",
                "\n",
                "    2 ruaccent  –Ω–µ—Å—É—â–µ—Å—Ç–≤—É—é—â–∏–µ —Å–ª–æ–≤–∞ –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –Ω–µ —Ç–∞–∫ –∫–∞–∫ –º–Ω–µ –Ω—É–∂–Ω–æ \n",
                "    –∑–∞—Å—Ç—Ä—è -> –∑+–∞—Å—Ç—Ä+—è (–¥–≤–∞ —É–¥–∞—Ä–µ–Ω–∏—è –≤ –¥–æ–≤–æ–ª—å–Ω–æ –∫–æ—Ä–æ—Ç–∫–æ–º —Å–ª–æ–≤–µ) \n",
                "    –æ–≤–∞–≤–∞—è -> –æ–≤–∞–≤–∞—è (–Ω–µ –ø—Ä–æ—Å—Ç–∞–≤–∏–ª —É–¥–∞—Ä–µ–Ω–∏—è)\n",
                "    3 —É–¥–∞—Ä–µ–Ω–∏–µ –≤ —Å–ª–æ–≤–∞—Ö —Å –Ω–µ—Å–∫–æ–ª—å–∫–∏–º–∏ —ë    –û–ë–´–ß–ù–û –ù–ê –í–¢–û–†–û–ï —ë.   —Ç—Ä—ë—Ö–≤–µ–¥–Å—Ä–Ω–æ–µ  (—Ç—Ä—ë—Ö–≤–Å–¥–µ—Ä–Ω–æ–µ) ...     (–Ω–æ —Å–Å–¥–∑—ë - —Å–¥–µ–ª–∞—Ç—å —Å–ø–∏—Å–æ–∫ –∏—Å–∫–ª—é—á–µ–Ω–∏–π)    –¢—ë–Å–ª—ë ?? —Ä–∞–π–æ–Ω –≤ –•–µ–ª—å—Å–∏–Ω–∫–∏ \n",
                "    4 –ï—Å–ª–∏ —Å–ª–æ–≤–æ –¥–æ–ø—É—Å–∫–∞–µ—Ç –Ω–µ—Å–∫–æ–ª—å–∫–æ –≤–∞—Ä–∏–∞–Ω—Ç–æ–≤ (–û–ú–û–ì–†–ê–§–´) ‚Äî –≤—ã–±–∏—Ä–∞–µ–º —á—ë—Ç–Ω–æ–µ \n",
                "\n",
                "    –†–µ–∞–ª–∏–∑—É–π—Ç–µ —Ñ—É–Ω–∫—Ü–∏—é –¥–ª—è –≤–≤–æ–¥–∞ —Ç–µ–∫—Å—Ç–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–º (–Ω–∞–ø—Ä–∏–º–µ—Ä, —á–µ—Ä–µ–∑ input –∏–ª–∏ –∑–∞–≥—Ä—É–∑–∫—É —Ñ–∞–π–ª–∞).  \n",
                "    \n",
                "    \n",
                "–¥–±   –î–û–ü–û–õ–ù–ò–¢–ï–õ–¨–ù–û\n",
                "1 –∞–Ω–∞–ª–∏–∑ –æ–¥–∏–Ω–∞–∫–æ–≤ –ª–∏ —Ä–∏—Ç–º –≤ —Å—Ç—Ä–æ–∫–∞—Ö, \n",
                "2 –µ—Å–ª–∏ —Ä–∞–∑–Ω—ã–π —Ç–æ –≥–∞—Ä–º–æ–Ω–∏—á–Ω–æ –ª–∏ —Å–æ—á–µ—Ç–∞–Ω–∏–µ —Ä–∏—Ç–º–æ–≤?\n",
                "    \n",
                "–ö–∞–∫ –ø—Ä–æ—Å—Ç–∞–≤–ª—è—Ç—å —É–¥–∞—Ä–µ–Ω–∏—è –≤ —Å–≤—è–∑–∫–µ –æ–¥–Ω–æ—Å–ª–æ–≥–æ–≤—ã—Ö —Å–ª–æ–≤?   + –ª–æ–≥–∏—á–µ—Å–∫–∏–µ —É–¥–∞—Ä–µ–Ω–∏—è (—Ç–∞–∫—Ç–æ–≤–æ–µ –∏ —Ñ—Ä–∞–∑–æ–≤–æ–µ)   + —Ä–∏—Ç–º–∏—á–µ—Å–∫–æ–π –∏–Ω–µ—Ä—Ü–∏–∏ (–ø–æ–¥—Å—Ç—Ä–æ–π–∫–∞ –ø–æ–¥ –ø—Ä–µ–¥—ã–¥—É—â–∏–µ —Å—Ç—Ä–æ–∫–∏)\n",
                "–û–¥–Ω–æ—Å–ª–æ–≥–æ–≤—ã–µ —Å–ª–æ–≤–∞ –≤ —Å—Ç—Ä–æ–∫–µ –Ω–∞ —á—ë—Ç–Ω–æ–º –º–µ—Å—Ç–µ –Ω–∞–∑–Ω–∞—á–∞—é —É–¥–∞—Ä–Ω—ã–º–∏. ( –Ω–æ —á–∞—Å—Ç–∏—Ü—ã, —Å–æ—é–∑—ã ... –æ–±—ã—á–Ω–æ –±–µ–∑ —É–¥–∞—Ä–µ–Ω–∏—è )\n",
                "\n",
                "-----------------------\n",
                "–†–ò–§–ú–´   (—Å–º rhythm.ipynb)\n",
                "–ø—Ä–æ—Å—Ç–µ–π—à–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞  (—Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ 2-—Ö –ø–æ—Å–ª–µ–¥–Ω–∏—Ö –±—É–∫–≤ –≤ –ø–æ—Å–ª–µ–¥–Ω–∏—Ö —Å–ª–æ–≤–∞—Ö —Å—Ç—Ä–æ–∫)\n",
                "def rhyme(a, b):\n",
                "    a = a.strip().split()[-1]\n",
                "    b = b.strip().split()[-1]\n",
                "    return a[-2:] == b[-2:]\n",
                "\n",
                "–í–∞—Ä–∏–∞–Ω—Ç 1: –°—Ä–∞–≤–Ω–µ–Ω–∏–µ –ø–æ –ø–æ—Å–ª–µ–¥–Ω–µ–º—É —Å–ª–æ–≥—É\n",
                "–≠—Ç–æ —á—É—Ç—å —Ç–æ—á–Ω–µ–µ, —á–µ–º –ø—Ä–æ—Å—Ç–æ –¥–≤–µ –±—É–∫–≤—ã:\n",
                "import re\n",
                "\n",
                "def get_last_syllable(word):\n",
                "    vowels = \"–∞–µ—ë–∏–æ—É—ã—ç—é—è\"\n",
                "    parts = re.findall(r'[–±–≤–≥–¥–∂–∑–π–∫–ª–º–Ω–ø—Ä—Å—Ç—Ñ—Ö—Ü—á—à—â]*[–∞–µ—ë–∏–æ—É—ã—ç—é—è]+', word.lower())\n",
                "    return parts[-1] if parts else word\n",
                "\n",
                "def rhyme(a, b):\n",
                "    a_last = get_last_syllable(a.strip().split()[-1])\n",
                "    b_last = get_last_syllable(b.strip().split()[-1])\n",
                "    return a_last == b_last\n",
                "\n",
                "–ü—Ä–∏–º–µ—Ä:\n",
                "rhyme(\"–¥–∞–≤–∞–π\", \"—Ç—Ä–∞–º–≤–∞–π\") ‚Üí True\n",
                "rhyme(\"–º–æ–ª–æ–∫–æ\", \"–æ–∫–Ω–æ\") ‚Üí False\n",
                "\n",
                "–í–∞—Ä–∏–∞–Ω—Ç 2: –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ —Ñ–æ–Ω–µ—Ç–∏–∫–∏ (—á–µ—Ä–µ–∑ –≤–Ω–µ—à–Ω–∏–µ –±–∏–±–ª–∏–æ—Ç–µ–∫–∏)\n",
                "–ï—Å–ª–∏ —Ç—ã —Ä–∞–±–æ—Ç–∞–µ—à—å —Å –∞–Ω–≥–ª–∏–π—Å–∫–∏–º, –º–æ–∂–Ω–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å pronouncing ‚Äî –æ–Ω–∞ –æ–ø–∏—Ä–∞–µ—Ç—Å—è –Ω–∞ —Ñ–æ–Ω–µ—Ç–∏—á–µ—Å–∫–∏–π —Å–ª–æ–≤–∞—Ä—å CMU:\n",
                "import pronouncing\n",
                "\n",
                "def rhyme_en(a, b):\n",
                "    a_phones = pronouncing.phones_for_word(a.lower())\n",
                "    b_phones = pronouncing.phones_for_word(b.lower())\n",
                "    if not a_phones or not b_phones:\n",
                "        return False\n",
                "    return pronouncing.rhymes(a.lower()).count(b.lower()) > 0\n",
                "\n",
                "\n",
                "–ù–æ –¥–ª—è —Ä—É—Å—Å–∫–æ–≥–æ —è–∑—ã–∫–∞ —Ç–∞–∫–∏—Ö –±–∏–±–ª–∏–æ—Ç–µ–∫ –º–µ–Ω—å—à–µ. –ú–æ–∂–Ω–æ –ø–æ–ø—Ä–æ–±–æ–≤–∞—Ç—å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å pymorphy2 –¥–ª—è –º–æ—Ä—Ñ–æ–ª–æ–≥–∏–∏, –Ω–æ —Ñ–æ–Ω–µ—Ç–∏–∫–∞ ‚Äî —ç—Ç–æ –æ—Ç–¥–µ–ª—å–Ω–∞—è –ø–µ—Å–Ω—è.\n",
                "\n",
                "–ê–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–∞: –°–ª–æ–≤–∞—Ä—å —Ä–∏—Ñ–º\n",
                "–ï—Å–ª–∏ —Ç—ã —Ö–æ—á–µ—à—å —Ç–æ—á–Ω—ã–µ —Ä–∏—Ñ–º—ã, –º–æ–∂–Ω–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –≥–æ—Ç–æ–≤—ã–µ —Å–ª–æ–≤–∞—Ä–∏ –∏–ª–∏ –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö —Ä–∏—Ñ–º. –ù–∞–ø—Ä–∏–º–µ—Ä, rifme.net –∏–ª–∏ rifmus.net ‚Äî –æ–Ω–∏ –¥–∞—é—Ç —Ä–∏—Ñ–º—ã –ø–æ –∑–≤—É—á–∞–Ω–∏—é, —É–¥–∞—Ä–µ–Ω–∏—é –∏ –¥–∞–∂–µ —Ç–µ–º–∞—Ç–∏–∫–µ.\n",
                "–•–æ—á–µ—à—å, —è –ø–æ–º–æ–≥—É —Ç–µ–±–µ –Ω–∞–ø–∏—Å–∞—Ç—å —Å–∫—Ä–∏–ø—Ç, –∫–æ—Ç–æ—Ä—ã–π –±—É–¥–µ—Ç –æ–±—Ä–∞—â–∞—Ç—å—Å—è –∫ –æ–¥–Ω–æ–º—É –∏–∑ —Ç–∞–∫–∏—Ö —Å–∞–π—Ç–æ–≤ –∏ –≤—ã—Ç–∞—Å–∫–∏–≤–∞—Ç—å —Ä–∏—Ñ–º—ã? –ò–ª–∏ –º–æ–∂–µ—Ç –±—ã—Ç—å, —Ç—ã —Ö–æ—á–µ—à—å –Ω–∞—Ç—Ä–µ–Ω–∏—Ä–æ–≤–∞—Ç—å —Å–≤–æ—é —Å–æ–±—Å—Ç–≤–µ–Ω–Ω—É—é –º–æ–¥–µ–ª—å —Ä–∏—Ñ–º –Ω–∞ –∫–æ—Ä–ø—É—Å–µ —Å—Ç–∏—Ö–æ–≤?\n",
                "\n",
                "–¥–±   \n",
                "((\n",
                "         1.   –∞–Ω–∞–ª–∏–∑ —Ä–∏—Ñ–º—ã 2 –∏ 4 —Å—Ç—Ä–æ–∫  –ø–æ –º–µ—Ç–æ–¥—É -\n",
                "–±—Ä–∞—Ç—å –ø–æ—Å–ª–µ–¥–Ω–µ–µ —Å–ª–æ–≤–æ —Å—Ç—Ä–æ–∫–∏, –∏–∑ –Ω–µ–≥–æ  –±—Ä–∞—Ç—å –∫—É—Å–æ–∫ –æ—Ç –ø–æ—Å–ª–µ–¥–Ω–µ–π –≥–ª–∞—Å–Ω–æ–π —Å–ª–æ–≤–∞ (–≤–∫–ª—é—á–∞—è –µ—ë) –∏ –¥–æ –∫–æ–Ω—Ü–∞ —Å–ª–æ–≤–∞. \n",
                "\"–æ—Ä–∫–µ—Å—Ç—Ä\" - \"–µ—Å—Ç—Ä\" (–∞ –ª—É—á—à–µ  \"–∫–µ—Å—Ç—Ä\".  –∑–∞—Ö–≤–∞—Ç—ã–≤–∞—è –ø—Ä–∏–ª–µ–≥–∞—é—â—É—é —Å–æ–≥–ª–∞—Å–Ω—É—é)\n",
                "–µ—Å–ª–∏ —Å—Ç—Ä–æ–∫–∞ –∑–∞–∫–∞–Ω—á–∏–≤–∞–µ—Ç—Å—è –Ω–∞ –æ–¥–Ω–æ–±—É–∫–≤–µ–Ω–Ω–æ–µ —Å–ª–æ–≤–æ —Å–æ–≥–ª–∞—Å–Ω—É—é, —Ç–æ –Ω—É–∂–Ω–æ –±—Ä–∞—Ç—å –∫—É—Å–æ–∫ –æ—Ç –ø–æ—Å–ª–µ–¥–Ω–µ–π –≥–ª–∞—Å–Ω–æ–π –ü–†–ï–î–ü–û–°–õ–ï–î–ù–ï–ì–û —Å–ª–æ–≤–∞ (–≤–∫–ª—é—á–∞—è –µ—ë) –∏ –¥–æ –∫–æ–Ω—Ü–∞ —Å–ª–æ–≤–∞                –∏ –ø—Ä–∏—Å–æ–µ–¥–∏–Ω–∏—Ç—å –∫ –Ω–µ–º—É  –æ–¥–Ω–æ–±—É–∫–≤–µ–Ω–Ω–æ–µ —Å–ª–æ–≤–æ —Å–æ–≥–ª–∞—Å–Ω—É—é\n",
                "\"–±–∞—Ä–∞–Ω –∫\" -  \"–∞–Ω–∫\"  (–∞ –ª—É—á—à–µ  \"—Ä–∞–Ω–∫\")\n",
                "\"–≤–µ—Å–Ω–∞ –≤\" - \"–∞–≤\"  (–∞ –ª—É—á—à–µ  \"–Ω–∞–≤\",   –µ—â—ë –ª—É—á—à–µ \"—Å–Ω–∞–≤\") \n",
                "  –µ—Å–ª–∏ —Å—Ç—Ä–æ–∫–∞ –∑–∞–∫–∞–Ω—á–∏–≤–∞–µ—Ç—Å—è –Ω–∞ –æ–¥–Ω–æ–±—É–∫–≤–µ–Ω–Ω–æ–µ —Å–ª–æ–≤–æ –≥–ª–∞—Å–Ω—É—é, —Ç–æ –Ω—É–∂–Ω–æ –±—Ä–∞—Ç—å –ø–æ—Å–ª–µ–¥–Ω—é—é –±—É–∫–≤—É –ü–†–ï–î–ü–û–°–õ–ï–î–ù–ï–ì–û —Å–ª–æ–≤–∞         –∏ –ø—Ä–∏—Å–æ–µ–¥–∏–Ω–∏—Ç—å –∫ –Ω–µ–º—É  –æ–¥–Ω–æ–±—É–∫–≤–µ–Ω–Ω–æ–µ —Å–ª–æ–≤–æ –≥–ª–∞—Å–Ω—É—é   –ï—Å–ª–∏ –∂–µ –ø–æ—Å–ª–µ–¥–Ω—è—è –±—É–∫–≤–∞ –ü–†–ï–î–ü–û–°–õ–ï–î–ù–ï–ì–û —Å–ª–æ–≤–∞ –Ω–µ –∑–≤—É—á–∞—â–∞—è (—ä,—å,) –∏–ª–∏ –≥–ª–∞—Å–Ω–∞—è, —Ç–æ –±–µ—Ä—ë–º –µ—â—ë –æ–¥–Ω—É –ø—Ä–µ–¥—ã–¥—É—â—É—é –±—É–∫–≤—É\n",
                "\"–¥–æ—á–µ–∫ –∞\" - \"–∫–∞\"    (–∞ –ª—É—á—à–µ  \"–µ–∫–∞\",   –µ—â—ë –ª—É—á—à–µ \"—á–µ–∫–∞\")  \n",
                "   (–ø—Ä–∏–º–µ—á–∞–Ω–∏–µ - –∏–∑–º–µ–Ω–∏—Ç—å –º–µ—Ç–æ–¥ –ø—Ä–∏—Ä–∞–≤–Ω–∏–≤–∞—è —Å—Ö–æ–∂–∏–µ –∑–≤—É–∫–∏ –∞-–æ, –∏-–µ, –µ-—é, –±-–ø, –≤-—Ñ, –≥-–∫-—Ö, –¥-—Ç, –∂-—à, –∑-—Å, –ª-–Ω-–º ... ) \n",
                "  2.  –æ—Ü–µ–Ω–∫–∞ –∞—Å—Å–æ–Ω–∞–Ω—Å–∞ \n",
                "  –µ—Å–ª–∏ —Ä–∏—Ñ–º–∞ –ø–æ –ø—É–Ω–∫—Ç—É 1 –Ω–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ —Ö–æ—Ä–æ—à–∞, —Ç–æ —Ä–∞—Å—Å–º–∞—Ç—Ä–∏–≤–∞–µ–º –∞—Å—Å–æ–Ω–∞–Ω—Å.\n",
                "–ø–æ—Å—á–∏—Ç–∞—Ç—å —á–∏—Å–ª–æ –±—É–∫–≤ 4-–π —Å—Ç—Ä–æ–∫–∏, –≤–∑—è—Ç—å —Å—Ç–æ–ª—å–∫–æ –∂–µ –≤–æ 2-–π. –ø–æ—Å—á–∏—Ç–∞—Ç—å  —Ä–∞—Å—Å—Ç–æ—è–Ω–∏–µ –õ–µ–≤–µ–Ω—à—Ç–µ–π–Ω–∞ –∏ –ø–æ –Ω–µ–º—É –æ—Ü–µ–Ω–∏–≤–∞—Ç—å  –∞—Å—Å–æ–Ω–∞–Ω—Å\n",
                "))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "id": "562f890c",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "—Å—ä–µ–¥+–∞–π—Ç–µ –≤ —á+–∞—Å –ø —á+–∞–π–Ω–æ–π –ª+–æ–∂–∫–µ\n",
                        "–∏ –±—É–¥—Ç –≤ –≥+–æ–ª–æ—Å–µ –º–µ—Ç+–∞–ª–ª\n",
                        "–¥+—É—Ö –∫–∞–ª–∏+–æ—Å—Ç—Ä–æ –ª–≤–∏—Ç+–∞–Ω—É\n",
                        "—Å—ä–µ–¥–ê–π—Ç–µ –≤ —á–ê—Å –ø —á–ê–π–Ω–æ–π –ª–û–∂–∫–µ\n",
                        "–∏ –±–£–¥—Ç –≤ –≥–û–ª–æ—Å–µ –º–µ—Ç–ê–ª–ª\n",
                        "–¥—É—Ö –∫–∞–ª–∏–û—Å—Ç—Ä–æ –ª–≤–∏—Ç–ê–Ω—É\n",
                        "–°—Ç—Ä–æ–∫–∞                        | –°–ª–æ–≥–æ–≤ | –£–¥–∞—Ä–Ω—ã–µ —Å–ª–æ–≥–∏ \n",
                        "-------------------------------------------------------\n",
                        "—Å—ä–µ–¥–ê–π—Ç–µ –≤ —á–ê—Å –ø —á–ê–π–Ω–æ–π –ª–û–∂–∫–µ |     üî¥8 | [2, 4, üî¥5, üî¥7]\n",
                        "–∏ –±–£–¥—Ç –≤ –≥–û–ª–æ—Å–µ –º–µ—Ç–ê–ª–ª        |     üî¥7 | [2, üî¥3, üî¥7]\n",
                        "–¥—É—Ö –∫–∞–ª–∏–û—Å—Ç—Ä–æ –ª–≤–∏—Ç–ê–Ω—É         |     üî¥8 | [4, üî¥7]\n",
                        "\n",
                        "=== –ü–†–û–í–ï–†–ö–ê –§–û–†–ú–´ ===\n",
                        "\n",
                        "\n",
                        "–ù–µ—Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ —Å—Ö–µ–º–µ (—Å—Ç—Ä–æ–∫–∞ ‚Ññ : —Ñ–∞–∫—Ç–∏—á–µ—Å–∫–æ–µ -> –æ–∂–∏–¥–∞–µ–º–æ–µ):\n",
                        "  1: 8 -> 9  |  —Å—ä–µ–¥–ê–π—Ç–µ –≤ —á–ê—Å –ø —á–ê–π–Ω–æ–π –ª–û–∂–∫–µ\n",
                        "  2: 7 -> 8  |  –∏ –±–£–¥—Ç –≤ –≥–û–ª–æ—Å–µ –º–µ—Ç–ê–ª–ª\n",
                        "  3: 8 -> 9  |  –¥—É—Ö –∫–∞–ª–∏–û—Å—Ç—Ä–æ –ª–≤–∏—Ç–ê–Ω—É\n",
                        "–°–±–æ–π —è–º–±–∞ ‚Äî –Ω–∞–π–¥–µ–Ω—ã –Ω–µ—á—ë—Ç–Ω—ã–µ —É–¥–∞—Ä–µ–Ω–∏—è:\n",
                        "  1: –Ω–µ—á—ë—Ç–Ω—ã–µ —É–¥–∞—Ä–Ω—ã–µ = [5, 7]  |  —Å—ä–µ–¥–ê–π—Ç–µ –≤ —á–ê—Å –ø —á–ê–π–Ω–æ–π –ª–û–∂–∫–µ\n",
                        "  2: –Ω–µ—á—ë—Ç–Ω—ã–µ —É–¥–∞—Ä–Ω—ã–µ = [3, 7]  |  –∏ –±–£–¥—Ç –≤ –≥–û–ª–æ—Å–µ –º–µ—Ç–ê–ª–ª\n",
                        "  3: –Ω–µ—á—ë—Ç–Ω—ã–µ —É–¥–∞—Ä–Ω—ã–µ = [7]  |  –¥—É—Ö –∫–∞–ª–∏–û—Å—Ç—Ä–æ –ª–≤–∏—Ç–ê–Ω—É\n",
                        "\n",
                        "=== –ö–æ–Ω–µ—Ü –ø—Ä–æ–≤–µ—Ä–∫–∏ ===\n",
                        "\n"
                    ]
                }
            ],
            "source": [
                "import re\n",
                "import regex\n",
                "from ruaccent import RUAccent\n",
                "\n",
                "# -----------------------------\n",
                "# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ RUAccent\n",
                "# -----------------------------\n",
                "accentizer = RUAccent()\n",
                "accentizer.load(omograph_model_size='turbo3.1',\n",
                "                use_dictionary=True,\n",
                "                tiny_mode=False)\n",
                "\n",
                "VOWELS = \"–∞–µ—ë–∏–æ—É—ã—ç—é—è–ê–ï–Å–ò–û–£–´–≠–Æ–Ø\"\n",
                "SCHEME = [9, 8, 9, 2]  # —Å—Ö–µ–º–∞ –ø–æ —Å–ª–æ–≥–∞–º\n",
                "\n",
                "text = \"\"\"\n",
                "    \t—Å—ä–µ–¥–∞–π—Ç–µ –≤ —á–∞—Å –ø —á–∞–π–Ω–æ–π –ª–æ–∂–∫–µ\n",
                "\t–∏ –±—É–¥—Ç –≤ –≥–æ–ª–æ—Å–µ –º–µ—Ç–∞–ª–ª\n",
                "\t–¥—É—Ö –∫–∞–ª–∏–æ—Å—Ç—Ä–æ –ª–≤–∏—Ç–∞–Ω—É\n",
                "\t\n",
                "\"\"\"\n",
                "\n",
                "\n",
                "# -----------------------------\n",
                "# –ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞\n",
                "# -----------------------------\n",
                "# –†–∞–∑–±–∏–≤–∞–µ–º –Ω–∞ —Å—Ç—Ä–æ–∫–∏ –∏ —É–¥–∞–ª—è–µ–º –≤—Å—ë –∫—Ä–æ–º–µ –±—É–∫–≤ –∏ –ø—Ä–æ–±–µ–ª–æ–≤,\n",
                "# —É–±–∏—Ä–∞–µ–º –ø—É—Å—Ç—ã–µ —Å—Ç—Ä–æ–∫–∏ –∏ –ø—Ä–∏–≤–æ–¥–∏–º –∫ –Ω–∏–∂–Ω–µ–º—É —Ä–µ–≥–∏—Å—Ç—Ä—É\n",
                "# –æ–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º —á–∏—Å–ª–æ —Å—Ç—Ä–æ–∫ –¥–ª–∏–Ω–æ–π —Å—Ö–µ–º—ã\n",
                "def normalize_lines(text: str, scheme_len: int) -> list[str]:\n",
                "    return [\n",
                "        regex.sub(\n",
                "            r'\\s+', ' ', regex.sub(r'[^\\p{L}\\s]', '', line)).strip().lower()\n",
                "        for line in text.splitlines() if line.strip()\n",
                "    ][:scheme_len]\n",
                "\n",
                "lines = normalize_lines(text, len(SCHEME))\n",
                "### print('\\n'.join(lines))\n",
                "\n",
                "# –†–∞—Å—Å—Ç–∞–Ω–æ–≤–∫–∞ —É–¥–∞—Ä–µ–Ω–∏–π\n",
                "def accentize_text(lines: list[str]) -> list[str]:\n",
                "    return [accentizer.process_all(line) for line in lines]\n",
                "accented = accentize_text(lines)\n",
                "print('\\n'.join(accented))\n",
                "\n",
                "\n",
                "# –ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ '+' –≤ –∑–∞–≥–ª–∞–≤–Ω—É—é –±—É–∫–≤—É\n",
                "def plus_to_upper(lines: list[str]) -> list[str]:\n",
                "    result = []\n",
                "    for line in lines:\n",
                "        chars = list(line)\n",
                "        out = []\n",
                "        skip = False\n",
                "        for i, ch in enumerate(chars):\n",
                "            if skip:\n",
                "                skip = False\n",
                "                continue\n",
                "            if ch == \"+\" and i + 1 < len(chars) and chars[i + 1] in VOWELS:\n",
                "                out.append(chars[i + 1].upper())  # —É–¥–∞—Ä–Ω–∞—è –±—É–∫–≤–∞ -> –∑–∞–≥–ª–∞–≤–Ω–∞—è\n",
                "                skip = True  # –ø—Ä–æ–ø—É—Å–∫–∞–µ–º —É–∂–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–Ω—É—é –±—É–∫–≤—É\n",
                "            else:\n",
                "                out.append(ch)\n",
                "        result.append(\"\".join(out))\n",
                "    return result\n",
                "accented_big = plus_to_upper(accented)\n",
                "### print('\\n'.join(accented_big))\n",
                "\n",
                "# –†–∞—Å—Å—Ç–∞–Ω–æ–≤–∫–∞ —É–¥–∞—Ä–µ–Ω–∏–π –≤ –æ–¥–Ω–æ—Å–ª–æ–≥–æ–≤—ã—Ö —Å–ª–æ–≤–∞—Ö (–ø—Ä–µ–∑—É–º–ø—Ü–∏—è —è–º–±–∞) –∏ —Å–ª–æ–≤–∞—Ö —Å \"—ë\"\n",
                "def accent_one_and_yo(lines: list[str]) -> list[str]:\n",
                "    result = []\n",
                "    for line in lines:\n",
                "        chars = list(line)\n",
                "        # –≥–ª–æ–±–∞–ª—å–Ω—ã–µ –ø–æ–∑–∏—Ü–∏–∏ –≤—Å–µ—Ö –≥–ª–∞—Å–Ω—ã—Ö\n",
                "        vowel_positions = [i for i, ch in enumerate(\n",
                "            chars) if ch.lower() in VOWELS]\n",
                "        vowel_order = {pos: idx for idx,\n",
                "                       pos in enumerate(vowel_positions, start=1)}\n",
                "\n",
                "        new_words = []\n",
                "        offset = 0\n",
                "        for word in line.split():\n",
                "            word_chars = list(word)\n",
                "            local_vowels = [i for i, ch in enumerate(\n",
                "                word_chars) if ch.lower() in VOWELS]\n",
                "            if len(local_vowels) == 1:  # —Å–ª–æ–≤–æ —Å –æ–¥–Ω–æ–π –≥–ª–∞—Å–Ω–æ–π\n",
                "                i = local_vowels[0]\n",
                "                ch = word_chars[i]\n",
                "                vpos_in_line = offset + i\n",
                "                order = vowel_order.get(vpos_in_line)\n",
                "                if order is not None:\n",
                "                    if order % 2 == 0:  # —á—ë—Ç–Ω—ã–π\n",
                "                        word_chars[i] = ch.upper()\n",
                "                    else:  # –Ω–µ—á—ë—Ç–Ω—ã–π\n",
                "                        word_chars[i] = ch.lower()\n",
                "            elif len(local_vowels) > 1:  # –Ω–µ—Å–∫–æ–ª—å–∫–æ –≥–ª–∞—Å–Ω—ã—Ö\n",
                "                for i, ch in enumerate(word_chars):\n",
                "                    if ch == \"—ë\":\n",
                "                        word_chars[i] = \"–Å\"\n",
                "            new_words.append(''.join(word_chars))\n",
                "            offset += len(word) + 1\n",
                "        result.append(' '.join(new_words))\n",
                "    return result\n",
                "accented_all = accent_one_and_yo(accented_big)\n",
                "print('\\n'.join(accented_all))\n",
                "\n",
                "\n",
                "\n",
                "# -----------------------------\n",
                "# –ü–†–û–í–ï–†–ö–ò –°–•–ï–ú\n",
                "# -----------------------------\n",
                "\n",
                "# —á–∏—Å–ª–æ —Å–ª–æ–≥–æ–≤\n",
                "def count_syllables(line: str) -> int:\n",
                "    return sum(1 for ch in line if ch in VOWELS)\n",
                "\n",
                "# –Ω–æ–º–µ—Ä–∞ —É–¥–∞—Ä–Ω—ã—Ö —Å–ª–æ–≥–æ–≤\n",
                "def line_stresses(line: str) -> list[int]:\n",
                "    stresses = []\n",
                "    syllable = 0\n",
                "    for ch in line:\n",
                "        if ch in VOWELS:\n",
                "            syllable += 1\n",
                "            if ch.isupper():  # —É–¥–∞—Ä–µ–Ω–∏–µ ‚Äî –∑–∞–≥–ª–∞–≤–Ω–∞—è –±—É–∫–≤–∞\n",
                "                stresses.append(syllable)\n",
                "    return stresses\n",
                "\n",
                "\n",
                "# —Ä–∞—Å—á—ë—Ç —Ä–µ–∞–ª—å–Ω–æ–π —Å—Ö–µ–º—ã —Å–ª–æ–≥–æ–≤ –∏ —É–¥–∞—Ä–µ–Ω–∏–π\n",
                "def analyze_poem_and_accents(accented_lines: list[str]):\n",
                "    \"\"\"–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –¥–≤–∞ —Å–ø–∏—Å–∫–∞:\n",
                "    - scheme_syllables: [–∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–ª–æ–≥–æ–≤ –≤ –∫–∞–∂–¥–æ–π —Å—Ç—Ä–æ–∫–µ]\n",
                "    - scheme_accents: [[–Ω–æ–º–µ—Ä–∞ —É–¥–∞—Ä–Ω—ã—Ö —Å–ª–æ–≥–æ–≤ –≤ —Å—Ç—Ä–æ–∫–µ1], [...], ...]\n",
                "    \"\"\"\n",
                "    scheme_syllables = [count_syllables(line) for line in accented_lines]\n",
                "    scheme_accents = [line_stresses(line) for line in accented_lines]\n",
                "    return scheme_syllables, scheme_accents\n",
                "\n",
                "# —Å—Ä–∞–≤–Ω–µ–Ω–∏–µ —Å—Ö–µ–º –∏ –∞–Ω–∞–ª–∏–∑ –æ—à–∏–±–æ–∫ (—Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –æ—Ç—á—ë—Ç–∞)\n",
                "def check_form(accented_lines: list[str], scheme_ref: list[int]):\n",
                "    \"\"\"–í—ã–ø–æ–ª–Ω—è–µ—Ç –ø—Ä–æ–≤–µ—Ä–∫—É —Ñ–æ—Ä–º—ã:\n",
                "    - —Å—Ä–∞–≤–Ω–∏–≤–∞–µ—Ç scheme_syllables —Å scheme_ref\n",
                "    - –Ω–∞—Ö–æ–¥–∏—Ç –Ω–µ—á—ë—Ç–Ω—ã–µ —É–¥–∞—Ä–Ω—ã–µ (—Å–±–æ–π —è–º–±–∞)\n",
                "    \"\"\"\n",
                "    SCHEME_SYLLABLES, SCHEME_ACCENTS = analyze_poem_and_accents(\n",
                "        accented_lines)\n",
                "\n",
                "    # 1) –Ω–µ—Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏—è —Å—Ö–µ–º–µ\n",
                "    mismatches = []\n",
                "    for i, syll_count in enumerate(SCHEME_SYLLABLES):\n",
                "        expected = scheme_ref[i] if i < len(scheme_ref) else None\n",
                "        if expected is None:\n",
                "            continue\n",
                "        if syll_count != expected:\n",
                "            mismatches.append({\n",
                "                \"line_no\": i + 1,\n",
                "                \"line\": accented_lines[i],\n",
                "                \"actual\": syll_count,\n",
                "                \"expected\": expected\n",
                "            })\n",
                "\n",
                "    # 2) —Å–±–æ–π —è–º–±–∞: –Ω–µ—á—ë—Ç–Ω—ã–µ —É–¥–∞—Ä–µ–Ω–∏—è\n",
                "    iamb_failures = []\n",
                "    for i, accents in enumerate(SCHEME_ACCENTS):\n",
                "        odd_accents = [a for a in accents if a % 2 == 1]\n",
                "        if odd_accents:\n",
                "            iamb_failures.append({\n",
                "                \"line_no\": i + 1,\n",
                "                \"line\": accented_lines[i],\n",
                "                \"odd_accents\": odd_accents,\n",
                "                \"all_accents\": accents\n",
                "            })\n",
                "    \n",
                "    return {\n",
                "        \"SCHEME_SYLLABLES\": SCHEME_SYLLABLES,\n",
                "        \"SCHEME_ACCENTS\": SCHEME_ACCENTS,\n",
                "        \"mismatches\": mismatches,\n",
                "        \"iamb_failures\": iamb_failures\n",
                "    }\n",
                "\n",
                "\n",
                "\n",
                "# -----------------------------\n",
                "# –ü–ï–ß–ê–¢–¨ –¢–ê–ë–õ–ò–¶  \n",
                "# -----------------------------\n",
                "\n",
                "_ANSI_RE = re.compile(r'\\033\\[[0-9;]*m')\n",
                "\n",
                "def visible_len(s: str) -> int:\n",
                "    return len(_ANSI_RE.sub('', s))\n",
                "\n",
                "def print_report_table(accented_lines: list[str], report: dict):\n",
                "    \"\"\"\n",
                "    –ü–µ—á–∞—Ç—å —Ä–æ–≤–Ω–æ–π —Ç–∞–±–ª–∏—Ü—ã:\n",
                "    accented_lines | SCHEME_SYLLABLES | SCHEME_ACCENTS\n",
                "    —Å –ø–æ–º–µ—Ç–∫–∞–º–∏ üî¥ –Ω–∞ –æ—Å–Ω–æ–≤–µ report['mismatches'] –∏ report['iamb_failures'].\n",
                "    –¥–±   –ú–æ–∂–Ω–æ –ª–∏ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å —Ç–∞–±–ª–∏—á–Ω—ã–π –º–æ–¥—É–ª—å?\n",
                "    –¥–±   –°–¥–µ–ª–∞—Ç—å –ø–æ–¥—Å–≤–µ—Ç–∫—É –Ω–∞—Ä—É—à–µ–Ω–∏–π –≤ —Ç–µ–∫—Å—Ç–µ.\n",
                "    \"\"\"\n",
                "    scheme_syllables = report[\"SCHEME_SYLLABLES\"]\n",
                "    scheme_accents = report[\"SCHEME_ACCENTS\"]\n",
                "    mismatches = report.get(\"mismatches\", [])\n",
                "    iamb_failures = report.get(\"iamb_failures\", [])\n",
                "\n",
                "    # –±—ã—Å—Ç—Ä—ã–π –¥–æ—Å—Ç—É–ø\n",
                "    mismatch_lines = {m['line_no'] for m in mismatches}\n",
                "    iamb_map = {f['line_no']: set(f['odd_accents']) for f in iamb_failures}\n",
                "\n",
                "    # —Å—Ñ–æ—Ä–º–∏—Ä—É–µ–º —Å—Ç—Ä–æ–∫–∏ —Ç–∞–±–ª–∏—Ü—ã\n",
                "    rows = []\n",
                "    for idx, line in enumerate(accented_lines):\n",
                "        line_no = idx + 1\n",
                "        syll = scheme_syllables[idx] if idx < len(scheme_syllables) else None\n",
                "        accs = scheme_accents[idx] if idx < len(scheme_accents) else []\n",
                "\n",
                "        # –ø–æ–º–µ—Ç–∫–∞ –≤ –∫–æ–ª–æ–Ω–∫–µ \"–°–ª–æ–≥–æ–≤\"\n",
                "        syll_disp = f\"üî¥{syll}\" if line_no in mismatch_lines else str(syll)\n",
                "\n",
                "        # –ø–æ–º–µ—Ç–∫–∏ –≤ –∫–æ–ª–æ–Ω–∫–µ \"–£–¥–∞—Ä–Ω—ã–µ —Å–ª–æ–≥–∏\"\n",
                "        acc_items = []\n",
                "        odd_set = iamb_map.get(line_no, set())\n",
                "        for a in accs:\n",
                "            acc_items.append(f\"üî¥{a}\" if a in odd_set else str(a))\n",
                "        accs_disp = \"[\" + \", \".join(acc_items) + \"]\"\n",
                "\n",
                "        rows.append((line, syll_disp, accs_disp))\n",
                "\n",
                "    # –≤—ã—á–∏—Å–ª—è–µ–º –≤–∏–¥–∏–º—ã–µ —à–∏—Ä–∏–Ω—ã –∫–æ–ª–æ–Ω–æ–∫\n",
                "    head1, head2, head3 = \"–°—Ç—Ä–æ–∫–∞\", \"–°–ª–æ–≥–æ–≤\", \"–£–¥–∞—Ä–Ω—ã–µ —Å–ª–æ–≥–∏\"\n",
                "    w_line = max(len(head1), max((visible_len(r[0]) for r in rows), default=0))\n",
                "    w_syll = max(len(head2),  max(\n",
                "        (visible_len(r[1]) for r in rows), default=0))\n",
                "    w_acc = max(len(head3),  max((visible_len(r[2]) for r in rows), default=0))\n",
                "\n",
                "    # –ø–µ—á–∞—Ç—å –∑–∞–≥–æ–ª–æ–≤–∫–∞ –∏ —Ä–∞–∑–¥–µ–ª–∏—Ç–µ–ª—è\n",
                "    print(f\"{head1:<{w_line}} | {head2:^{w_syll}} | {head3:<{w_acc}}\")\n",
                "    print(\"-\" * (w_line + 3 + w_syll + 3 + w_acc))\n",
                "\n",
                "    # –ø–µ—á–∞—Ç—å —Å—Ç—Ä–æ–∫ —Å –ø–æ–¥—Å—á—ë—Ç–æ–º –ø–∞–¥–¥–∏–Ω–≥–∞ –ø–æ –≤–∏–¥–∏–º–æ–π –¥–ª–∏–Ω–µ\n",
                "    for line, syll_disp, accs_disp in rows:\n",
                "        pad1 = w_line - visible_len(line)\n",
                "        pad2 = w_syll - visible_len(syll_disp)\n",
                "        print(f\"{line}{' '*pad1} | {' '*pad2}{syll_disp} | {accs_disp}\")\n",
                "\n",
                "\n",
                "# -----------------------------\n",
                "# –ü–ï–ß–ê–¢–¨ –û–¢–ß–Å–¢–û–í\n",
                "# -----------------------------\n",
                "def print_report_summary(report: dict):\n",
                "    \"\"\"\n",
                "    –ü–µ—á–∞—Ç–∞–µ—Ç —Ç–µ–∫—Å—Ç–æ–≤—ã–π –∫—Ä–∞—Ç–∫–∏–π –æ—Ç—á—ë—Ç: SCHEME_SYLLABLES, SCHEME_ACCENTS,\n",
                "    —Å–ø–∏—Å–æ–∫ –Ω–µ—Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–π –∏ —Å–±–æ–∏ —è–º–±–∞ (–∏–∑ report).\n",
                "    \"\"\"\n",
                "    ## SCHEME_SYLLABLES = report[\"SCHEME_SYLLABLES\"]\n",
                "    ## SCHEME_ACCENTS = report[\"SCHEME_ACCENTS\"]\n",
                "    mismatches = report.get(\"mismatches\", [])\n",
                "    iamb_failures = report.get(\"iamb_failures\", [])\n",
                "\n",
                "    print(\"\\n=== –ü–†–û–í–ï–†–ö–ê –§–û–†–ú–´ ===\\n\")\n",
                "    ## print(\"SCHEME_SYLLABLES:\", SCHEME_SYLLABLES)\n",
                "    ## print(\"SCHEME_ACCENTS:  \", SCHEME_ACCENTS)\n",
                "    print()\n",
                "\n",
                "    if mismatches:\n",
                "        print(\"–ù–µ—Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ —Å—Ö–µ–º–µ (—Å—Ç—Ä–æ–∫–∞ ‚Ññ : —Ñ–∞–∫—Ç–∏—á–µ—Å–∫–æ–µ -> –æ–∂–∏–¥–∞–µ–º–æ–µ):\")\n",
                "        for m in mismatches:\n",
                "            print(\n",
                "                f\" {m['line_no']:>2}: {m['actual']} -> {m['expected']}  |  {m['line']}\")\n",
                "    else:\n",
                "        print(\"–ù–µ—Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–π —Å—Ö–µ–º–µ: –Ω–µ—Ç\")\n",
                "\n",
                "    if iamb_failures:\n",
                "        print(\"–°–±–æ–π —è–º–±–∞ ‚Äî –Ω–∞–π–¥–µ–Ω—ã –Ω–µ—á—ë—Ç–Ω—ã–µ —É–¥–∞—Ä–µ–Ω–∏—è:\")\n",
                "        for f in iamb_failures:\n",
                "            print(\n",
                "                f\" {f['line_no']:>2}: –Ω–µ—á—ë—Ç–Ω—ã–µ —É–¥–∞—Ä–Ω—ã–µ = {f['odd_accents']}  |  {f['line']}\")\n",
                "    else:\n",
                "        print(\"–°–±–æ–π —è–º–±–∞: –Ω–µ—Ç\")\n",
                "\n",
                "    print(\"\\n=== –ö–æ–Ω–µ—Ü –ø—Ä–æ–≤–µ—Ä–∫–∏ ===\\n\")\n",
                "\n",
                "\n",
                "# –ø–æ–ª—É—á–∞–µ–º –∞–Ω–∞–ª–∏—Ç–∏—á–µ—Å–∫–∏–π report (check_form –¥–æ–ª–∂–µ–Ω –≤–æ–∑–≤—Ä–∞—â–∞—Ç—å –¥–∞–Ω–Ω—ã–µ –∏ –º–æ–∂–µ—Ç –Ω–µ –ø–µ—á–∞—Ç–∞—Ç—å —Å–∞–º)\n",
                "report = check_form(accented_all, SCHEME)\n",
                "\n",
                "# –ø–µ—á–∞—Ç—å —Ä–æ–≤–Ω–æ–π —Ç–∞–±–ª–∏—Ü—ã\n",
                "print_report_table(accented_all, report)\n",
                "\n",
                "# –ø–µ—á–∞—Ç—å —Ç–µ–∫—Å—Ç–æ–≤–æ–≥–æ —Å–≤–æ–¥–Ω–æ–≥–æ –æ—Ç—á—ë—Ç–∞\n",
                "print_report_summary(report)"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": ".venv",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.12.10"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}
